{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensor_comprehensions as tc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as recommended by the authors for better performance\n",
    "tune_settings = {\n",
    "    \"threads\": 32,\n",
    "    \"generations\": 5,\n",
    "    \"pop_size\": 15,\n",
    "    \"number_elites\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gconv_lang = tc.database['group_convolution']['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try the sizes given in the paper\n",
    "# N = 32, G = 32, F = 16, C = 16, W = 14, H = 14\n",
    "\n",
    "I = torch.randn(32, 32, 16, 14, 14).cuda()\n",
    "W1 = torch.randn(32, 16, 16, 3, 3).cuda()\n",
    "B = torch.randn(32, 16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gconv = tc.define(gconv_lang, name='group_convolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Autotuning cache will be saved to: cache/tall_conv.tc.cuda/options\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensor_comprehensions.mapping_options.Options at 0x7f57959cb148>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gconv.autotune(I, W1, B,\n",
    "               cache='cache/gconv1.tc',\n",
    "               **tune_settings,\n",
    "               options=tc.Options('conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 86, 222])\n"
     ]
    }
   ],
   "source": [
    "# run twice to prep cuda\n",
    "out = gconv(I, W1, B, cache='cache/gconv1.tc')\n",
    "torch.cuda.synchronize()\n",
    "out = gconv(I, W1, B, cache='cache/gconv1.tc')\n",
    "torch.cuda.synchronize()\n",
    "print(out.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 8.214661343\n",
      "[ 0.01603009  0.01610681  0.01728153]\n"
     ]
    }
   ],
   "source": [
    "# test performance using TC\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "timings = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    start = time.perf_counter()\n",
    "    output = gconv(I, W1, B, cache='cache/gconv1.tc')\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 1.312579019\n",
      "[ 0.00256825  0.00258939  0.00277763]\n"
     ]
    }
   ],
   "source": [
    "# test the torch equivalent\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, groups=32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "CN = ConvNet()\n",
    "CN.cuda()\n",
    "\n",
    "var_input = Variable(torch.randn(32, 512, 14, 14).cuda())\n",
    "# run a couple times to work out start hiccups\n",
    "CN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "CN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# test performance\n",
    "timings = np.zeros(50)\n",
    "\n",
    "for i in range(50):\n",
    "    start = time.perf_counter()\n",
    "    output = CN(var_input)\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
