{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensor_comprehensions as tc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as recommended by the authors for better performance\n",
    "tune_settings = {\n",
    "    \"threads\": 32,\n",
    "    \"generations\": 7,\n",
    "    \"pop_size\": 15,\n",
    "    \"number_elites\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# heavier options\n",
    "tune_settings = {\n",
    "    \"threads\": 32,\n",
    "    \"generations\": 20,\n",
    "    \"pop_size\": 50,\n",
    "    \"number_elites\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_lang = tc.database['convolution_strided']['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try some different sizes\n",
    "\n",
    "I = torch.randn(512, 3, 20, 20).cuda()\n",
    "W1 = torch.randn(6, 3, 3, 3).cuda()\n",
    "B = torch.randn(6).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv = tc.define(conv_lang.format(sh=3, sw=3), name='convolution_strided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Autotuning cache will be saved to: cache/large_batch.tc.cuda/options\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensor_comprehensions.mapping_options.Options at 0x7fef980ed730>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = tc.define(conv_lang.format(sh=3, sw=3), name='convolution_strided')\n",
    "conv.autotune(I, W1, B,\n",
    "              cache='cache/large_batch.tc',\n",
    "              **tune_settings,\n",
    "              options=tc.Options('conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 6, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# run twice to prep cuda\n",
    "out = conv(I, W1, B, cache='cache/large_batch.tc')\n",
    "torch.cuda.synchronize()\n",
    "print(out.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.104475689005\n",
      "[  6.14650000e-05   8.17290002e-05   1.49113200e-04]\n"
     ]
    }
   ],
   "source": [
    "# test performance using TC\n",
    "output = torch.zeros(512, 6, 6, 6).cuda()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "timings = np.zeros(1000)\n",
    "\n",
    "for i in range(1000):\n",
    "    start = time.perf_counter()\n",
    "    output = conv(I, W1, B, cache='cache/large_batch.tc')\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 0.00830888600171\n",
      "[  7.16190000e-05   7.70214999e-05   1.04412000e-04]\n"
     ]
    }
   ],
   "source": [
    "# test the torch equivalent\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, (3, 3), stride=(3, 3)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "CN = ConvNet()\n",
    "CN.cuda()\n",
    "\n",
    "var_input = Variable(torch.randn(512, 3, 20, 20).cuda())\n",
    "# run a couple times to work out start hiccups\n",
    "CN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "CN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# test performance\n",
    "timings = np.zeros(100)\n",
    "\n",
    "for i in range(100):\n",
    "    start = time.perf_counter()\n",
    "    output = CN(var_input)\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
