{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensor_comprehensions as tc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as recommended by the authors for better performance\n",
    "tune_settings = {\n",
    "    \"threads\": 32,\n",
    "    \"generations\": 8,\n",
    "    \"pop_size\": 25,\n",
    "    \"number_elites\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobilenet_lang = tc.database['small_mobilenet']['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tune mobilenet for the dimensions typical of mobilenet\n",
    "\n",
    "I = torch.randn(128, 56, 56).cuda()\n",
    "W1 = torch.randn(128, 3, 3).cuda()\n",
    "B1 = torch.randn(128).cuda()\n",
    "W2 = torch.randn(128, 128).cuda()\n",
    "B2 = torch.randn(128).cuda()\n",
    "\n",
    "small_mobilenet = tc.define(mobilenet_lang, name='small_mobilenet')\n",
    "small_mobilenet.autotune(I, W1, B1, W2, B2,\n",
    "                         cache='cache/small_mobilenet_128_56_3_128',\n",
    "                         **tune_settings,\n",
    "                         options=tc.Options('conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run twice to prep cuda\n",
    "\n",
    "small_mobilenet(I, W1, B1, W2, B2, cache='cache/small_mobilenet_128_56_3_128.tc')\n",
    "torch.cuda.synchronize()\n",
    "small_mobilenet(I, W1, B1, W2, B2, cache='cache/small_mobilenet_128_56_3_128.tc')\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test performance using TC\n",
    "\n",
    "output = torch.zeros(128, 56, 56).cuda()\n",
    "\n",
    "timings = np.zeros(1000)\n",
    "\n",
    "for i in range(1000):\n",
    "    start = time.perf_counter()\n",
    "    tbmm(I, W1, B1, W2, B2,\n",
    "         cache='cache/small_mobilenet_128_56_3_128.tc', \n",
    "         outputs=output)\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the torch equivalent\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 3, padding=1, groups=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 1, padding=0),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "MN = MobileNet()\n",
    "\n",
    "var_input = Variable(torch.randn(1, 128, 56, 56))\n",
    "# run a couple times to work out start hiccups\n",
    "MN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "MN(var_input)\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "# test performance\n",
    "timings = np.zeros(1000)\n",
    "output = torch.randn(1, 128, 56, 56).cuda()\n",
    "\n",
    "for i in range(1000):\n",
    "    start = time.perf_counter()\n",
    "    output = MN(var_input)\n",
    "    torch.cuda.synchronize()\n",
    "    timings[i] = time.perf_counter() - start\n",
    "\n",
    "total_elapsed = np.sum(timings)\n",
    "print('total time: ' + str(total_elapsed))\n",
    "\n",
    "# get percentile statistics\n",
    "percentiles = np.percentile(timings, [0, 50, 90])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
